<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>60f9edc84d8f4d4f9db6bde684094604</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      word-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="machine-learning---boosting" class="cell markdown" id="LTs7BG93CbmP">
<h1>Machine Learning - Boosting</h1>
<h2 id="masaccio-braun">Masaccio Braun</h2>
<p>In the past, we have used machine learning methods that implement a single <em>learner</em> i.e. linear regressor, decision tree regressor, etc., as well as learning methods that implement multiple learners i.e. random forest regressor. Random forest models are known as 'ensemble' methods because they use a group of learners to enhance the performance of each individual learner and create a stronger, aggregate model. However, many of the individual learners in the ensemble tend to be <em>weak learners</em>, such that some tend to make poor predictions based on the observations they are specifically trained on. One way to combat this is through <strong>boosting</strong>. Boosting is a derivative of bagging, in which weak learners are trained simultaneously through a random selection, each having equal <em>weight</em> in predictive capability. Boosting differs in that the models have differing weights, since they are trained sequentially to compensate for weak learners by taking the efficacy of the previous model and increasing the weights of the data that the previous model had the highest error with.</p>
<p><img src="vertopal_36b40601c4794c6b8b7ee372dc698101/51c38e45f67558ed3101666399d0813b72394fd7.png" alt="boostingvsbagging" /></p>
<p>Source: <a href="https://towardsdatascience.com/what-is-boosting-in-machine-learning-2244aa196682" class="uri">https://towardsdatascience.com/what-is-boosting-in-machine-learning-2244aa196682</a></p>
<p>There are a multitude of methods that can be implemented to boost a model. In this exploration, I will test a random forest booster and a decision tree booster for locally weighted regression and a version of extreme gradient boosting regression, and compare the results of their predictions in two multivariate analyses.</p>
</section>
<div class="cell code" data-execution_count="37" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="cT6eOh_GNtFk" data-outputId="317d34ee-c6e4-4aec-ea64-5bf8cdcbf4d8">
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Update statsmodels</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> pip install statsmodels<span class="op">==</span><span class="fl">0.13.2</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: statsmodels==0.13.2 in /usr/local/lib/python3.7/dist-packages (0.13.2)
Requirement already satisfied: scipy&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from statsmodels==0.13.2) (1.4.1)
Requirement already satisfied: packaging&gt;=21.3 in /usr/local/lib/python3.7/dist-packages (from statsmodels==0.13.2) (21.3)
Requirement already satisfied: pandas&gt;=0.25 in /usr/local/lib/python3.7/dist-packages (from statsmodels==0.13.2) (1.3.5)
Requirement already satisfied: patsy&gt;=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels==0.13.2) (0.5.2)
Requirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.7/dist-packages (from statsmodels==0.13.2) (1.21.5)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging&gt;=21.3-&gt;statsmodels==0.13.2) (3.0.7)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.25-&gt;statsmodels==0.13.2) (2.8.2)
Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.25-&gt;statsmodels==0.13.2) (2018.9)
Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy&gt;=0.5.2-&gt;statsmodels==0.13.2) (1.15.0)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="1" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="lXnt67te04-C" data-outputId="c21913aa-57b2-41fd-8eed-27c379c1fd2d">
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Imports</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># General libraries</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib <span class="im">as</span> mpl</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear algebra</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.linalg <span class="im">import</span> lstsq</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.sparse.linalg <span class="im">import</span> lsmr</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Interpolators</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.interpolate <span class="im">import</span> interp1d, griddata, LinearNDInterpolator, NearestNDInterpolator</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Scalers</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Cross Validation</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Model Evaluation</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error <span class="im">as</span> mse</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error <span class="im">as</span> mae</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score <span class="im">as</span> r2</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Regressors</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression, Lasso, Ridge, ElasticNet</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.nonparametric.kernel_regression <span class="im">import</span> KernelReg</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBRegressor</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Neural Network</span></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.models <span class="im">import</span> Sequential</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Dense, Dropout</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.callbacks <span class="im">import</span> EarlyStopping</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.optimizers <span class="im">import</span> Adam</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.
  import pandas.util.testing as tm
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="2" id="YKCq8GOt3tf4">
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># High-resolution images</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_format <span class="op">=</span> <span class="st">&#39;retina&#39;</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>mpl.rcParams[<span class="st">&#39;figure.dpi&#39;</span>] <span class="op">=</span> <span class="dv">120</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="3" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="UX7Al8yf3phd" data-outputId="9da905c4-d083-45ea-d616-e9b47d6f0c24">
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Mount Google Drive</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> drive</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>drive.mount(<span class="st">&#39;/content/drive&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Mounted at /content/drive
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="4" id="9JFXnqie3pk_">
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Tricubic Kernel</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Tricubic(x):</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(x.shape) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> x.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  d <span class="op">=</span> np.sqrt(np.<span class="bu">sum</span>(x<span class="op">**</span><span class="dv">2</span>,axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> np.where(d<span class="op">&gt;</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">70</span><span class="op">/</span><span class="dv">81</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>d<span class="op">**</span><span class="dv">3</span>)<span class="op">**</span><span class="dv">3</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Quartic Kernel</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Quartic(x):</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(x.shape) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> x.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  d <span class="op">=</span> np.sqrt(np.<span class="bu">sum</span>(x<span class="op">**</span><span class="dv">2</span>,axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> np.where(d<span class="op">&gt;</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">15</span><span class="op">/</span><span class="dv">16</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>d<span class="op">**</span><span class="dv">2</span>)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Epanechnikov Kernel</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Epanechnikov(x):</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(x.shape) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> x.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>  d <span class="op">=</span> np.sqrt(np.<span class="bu">sum</span>(x<span class="op">**</span><span class="dv">2</span>,axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> np.where(d<span class="op">&gt;</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">3</span><span class="op">/</span><span class="dv">4</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>d<span class="op">**</span><span class="dv">2</span>)) </span></code></pre></div>
</div>
<section id="boston-housing-prices" class="cell markdown" id="BUf-LB0lCfUD">
<h3>Boston Housing Prices</h3>
<p>The first dataset I will try to model will be the Boston Housing Prices dataset, which can be found here: <a href="https://www.kaggle.com/prasadperera/the-boston-housing-dataset" class="uri">https://www.kaggle.com/prasadperera/the-boston-housing-dataset</a></p>
</section>
<div class="cell code" data-execution_count="5" data-colab="{&quot;height&quot;:270,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="1O3cHZTd3poB" data-outputId="ef115222-7916-472b-82ec-b1c19c969a39">
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>houses <span class="op">=</span> pd.read_csv(<span class="st">&#39;drive/MyDrive/Data/Boston Housing Prices.csv&#39;</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>houses.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="5">

  <div id="df-ef4c7c52-ab5d-49c8-b926-3ba678aca45d">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>town</th>
      <th>tract</th>
      <th>longitude</th>
      <th>latitude</th>
      <th>crime</th>
      <th>residential</th>
      <th>industrial</th>
      <th>river</th>
      <th>nox</th>
      <th>rooms</th>
      <th>older</th>
      <th>distance</th>
      <th>highway</th>
      <th>tax</th>
      <th>ptratio</th>
      <th>lstat</th>
      <th>cmedv</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Nahant</td>
      <td>2011</td>
      <td>-70.955002</td>
      <td>42.255001</td>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>no</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.199997</td>
      <td>4.0900</td>
      <td>1</td>
      <td>296</td>
      <td>15.300000</td>
      <td>4.98</td>
      <td>24.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Swampscott</td>
      <td>2021</td>
      <td>-70.949997</td>
      <td>42.287498</td>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>no</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.900002</td>
      <td>4.9671</td>
      <td>2</td>
      <td>242</td>
      <td>17.799999</td>
      <td>9.14</td>
      <td>21.600000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Swampscott</td>
      <td>2022</td>
      <td>-70.935997</td>
      <td>42.283001</td>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>no</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.099998</td>
      <td>4.9671</td>
      <td>2</td>
      <td>242</td>
      <td>17.799999</td>
      <td>4.03</td>
      <td>34.700001</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Marblehead</td>
      <td>2031</td>
      <td>-70.928001</td>
      <td>42.292999</td>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>no</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.799999</td>
      <td>6.0622</td>
      <td>3</td>
      <td>222</td>
      <td>18.700001</td>
      <td>2.94</td>
      <td>33.400002</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Marblehead</td>
      <td>2032</td>
      <td>-70.921997</td>
      <td>42.298000</td>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>no</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.200001</td>
      <td>6.0622</td>
      <td>3</td>
      <td>222</td>
      <td>18.700001</td>
      <td>5.33</td>
      <td>36.200001</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-ef4c7c52-ab5d-49c8-b926-3ba678aca45d')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-ef4c7c52-ab5d-49c8-b926-3ba678aca45d button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-ef4c7c52-ab5d-49c8-b926-3ba678aca45d');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell markdown" id="DWTWDD5hP4U2">
<p>For the multivariate analysis, I will choose 3 feature variables to predict the median value of owner occupied homes: average number of rooms per dwelling, per capita crime rate by town, and full-value property tax rate. To get an idea of the immediate linear correlation coefficients of the feature and response variables, I will create a heatmap.</p>
</div>
<div class="cell code" data-execution_count="57" data-colab="{&quot;height&quot;:852,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="0L_zDpj53pq9" data-outputId="6bcc64dd-3932-4d46-c712-6cf7345aafc2">
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Select variables and plot data</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> houses[[<span class="st">&#39;rooms&#39;</span>, <span class="st">&#39;crime&#39;</span>, <span class="st">&#39;tax&#39;</span>]].values</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> houses[<span class="st">&#39;cmedv&#39;</span>].values</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlation Heatmap</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>irrel_col <span class="op">=</span> [<span class="st">&#39;town&#39;</span>,<span class="st">&#39;tract&#39;</span>,<span class="st">&#39;longitude&#39;</span>,<span class="st">&#39;latitude&#39;</span>,<span class="st">&#39;residential&#39;</span>,<span class="st">&#39;industrial&#39;</span>,<span class="st">&#39;river&#39;</span>,<span class="st">&#39;nox&#39;</span>,<span class="st">&#39;distance&#39;</span>,<span class="st">&#39;older&#39;</span>,<span class="st">&#39;highway&#39;</span>,<span class="st">&#39;ptratio&#39;</span>,<span class="st">&#39;lstat&#39;</span>]</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>houses_select <span class="op">=</span> houses.drop(columns<span class="op">=</span>irrel_col)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> houses_select.corr()</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> np.triu(c)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">8</span>))</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>sns.heatmap(c, mask<span class="op">=</span>mask, annot<span class="op">=</span><span class="va">True</span>, annot_kws<span class="op">=</span>{<span class="st">&#39;fontsize&#39;</span>:<span class="dv">8</span>,<span class="st">&#39;weight&#39;</span>:<span class="st">&#39;bold&#39;</span>}, cmap<span class="op">=</span><span class="st">&#39;BuPu&#39;</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>            yticklabels<span class="op">=</span>[<span class="st">&#39; &#39;</span>] <span class="op">+</span> <span class="bu">list</span>(houses_select.columns[<span class="dv">1</span>:]), xticklabels<span class="op">=</span>houses_select.columns[:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>plt.tick_params(size<span class="op">=</span><span class="dv">0</span>, labelsize<span class="op">=</span><span class="dv">14</span>, pad<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Pairwise Linear Correlations&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;houses_heat.png&#39;</span>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_36b40601c4794c6b8b7ee372dc698101/25f9d79aa57e51d123a8b78bb0cc4035ce7994a8.png" width="786" height="835" /></p>
</div>
</div>
<div class="cell markdown" id="2g_4dVJwChRt">
<p>The only feature that seems to hold any significant linear correlation to median house price is the number of rooms. Just to get an idea of the distribution of the variables, I will create a pairplot of the relevant data fields.</p>
</div>
<div class="cell code" data-execution_count="7" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="6lOnC5V-3pwN" data-outputId="82222522-5e22-4e9d-cb49-b07d3135fa3b">
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">8</span>))</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>sns.pairplot(houses_select)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;houses_pair.png&#39;</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<pre><code>&lt;Figure size 960x960 with 0 Axes&gt;</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_36b40601c4794c6b8b7ee372dc698101/521d5d28703d9daccd0edd091f769f906f0442ae.png" width="1182" height="1180" /></p>
</div>
</div>
<div class="cell code" data-execution_count="8" id="9GB1eum7Ef2h">
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardization</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>ss <span class="op">=</span> StandardScaler()</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="9" id="U7MHMSxdEf5X">
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cross Validation</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>kf <span class="op">=</span> KFold(n_splits<span class="op">=</span>k, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">410</span>)</span></code></pre></div>
</div>
<div class="cell markdown" id="PmBEpZP0CmR9">
<p>To compare against the boosted models, I will be testing an ordinary least-squares linear regression, a decision tree regression, and a random forest regression, as well as an artificial neural network, though I suspect this will perform the poorly.</p>
</div>
<div class="cell code" data-execution_count="10" id="eMt-SfmaKXR0">
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Least Squares Regression</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>lsr <span class="op">=</span> LinearRegression()</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="11" id="DdiYS7UpD0Fp">
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Decision Tree Regression</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>dtr <span class="op">=</span> DecisionTreeRegressor(max_depth<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">410</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="12" id="GH3KO88YD-qe">
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest Regression</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>rfr <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">50</span>, max_depth<span class="op">=</span><span class="dv">2</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="16" id="fEEiIBmXMFjj">
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Neural Network</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>seq <span class="op">=</span> Sequential()</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>seq.add(Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>))</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>seq.add(Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>))</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>seq.add(Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>))</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>seq.add(Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">&quot;linear&quot;</span>))</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>seq.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">&#39;mean_squared_error&#39;</span>, optimizer<span class="op">=</span>Adam(learning_rate<span class="op">=</span><span class="fl">1e-2</span>))</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>es <span class="op">=</span> EarlyStopping(monitor<span class="op">=</span><span class="st">&#39;val_loss&#39;</span>, mode<span class="op">=</span><span class="st">&#39;min&#39;</span>, verbose<span class="op">=</span><span class="dv">1</span>, patience<span class="op">=</span><span class="dv">800</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="14" id="jXKBkJ1X3p6A">
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Locally Weighted Regression</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lwr(X, y, xnew, kern, tau, intercept, boost<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(X) </span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    yest <span class="op">=</span> np.zeros(n)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(y.shape)<span class="op">==</span><span class="dv">1</span>: </span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>      y <span class="op">=</span> y.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(X.shape)<span class="op">==</span><span class="dv">1</span>:</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>      X <span class="op">=</span> X.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> intercept:</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>      X1 <span class="op">=</span> np.column_stack([np.ones((<span class="bu">len</span>(X),<span class="dv">1</span>)),X])</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>      X1 <span class="op">=</span> X</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> np.array([kern((X <span class="op">-</span> X[i])<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>tau)) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n)])</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):          </span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>        W <span class="op">=</span> np.diag(w[:,i])</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>        b <span class="op">=</span> np.transpose(X1).dot(W).dot(y)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>        A <span class="op">=</span> np.transpose(X1).dot(W).dot(X1)</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>        beta, res, rnk, s <span class="op">=</span> lstsq(A, b)</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>        yest[i] <span class="op">=</span> np.dot(X1[i],beta)</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> X.shape[<span class="dv">1</span>]<span class="op">==</span><span class="dv">1</span>:</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>      f <span class="op">=</span> interp1d(X.flatten(),yest,fill_value<span class="op">=</span><span class="st">&#39;extrapolate&#39;</span>)</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>      f <span class="op">=</span> LinearNDInterpolator(X, yest)</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> f(xnew) </span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">sum</span>(np.isnan(output))<span class="op">&gt;</span><span class="dv">0</span>:</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>      g <span class="op">=</span> NearestNDInterpolator(X,y.ravel()) </span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>      output[np.isnan(output)] <span class="op">=</span> g(xnew[np.isnan(output)])</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> output</span></code></pre></div>
</div>
<section id="locally-weighted-regression-boosting" class="cell markdown" id="C8ElKZMcCvP1">
<h2>Locally Weighted Regression Boosting</h2>
</section>
<div class="cell code" data-execution_count="15" id="0j67GP9f3p8J">
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Boosted Locally Weighted Regression</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> blwr(X, y, xnew, kern, tau, intercept, boost):</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>  Fx <span class="op">=</span> lwr(X,y,X,kern,tau,intercept)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>  new_y <span class="op">=</span> y <span class="op">-</span> Fx</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  boost.fit(X,new_y)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>  output <span class="op">=</span> boost.predict(xnew) <span class="op">+</span> lwr(X,y,xnew,kern,tau,intercept)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> output </span></code></pre></div>
</div>
<section id="extreme-gradient-boosting" class="cell markdown" id="Oj_Jh_F0Cvzv">
<h2>Extreme Gradient Boosting</h2>
<p>A derivative of gradient boosting. In this method, a set of parallel decision trees are fitted to the residuals of the previous trees' predictions, so it is an ensemble model similar to random forest. However, instead of relying on traditional decision trees, XGB uses <em>XGBoost trees</em>, which are created by calculating <em>similarity scores</em> between the observations of the leaf nodes. Furthermore, XGB implements regularization to prevent overfitting of the individual decision trees. With XGB, the process of sequentially creating weak models is done so as a <em>gradient descent</em> algorithm using an objective cost function, in which the algorithm iterates until the cost function is at close to or equal to zero, or at least at the lowest minima. In order to minimize the loss function,we take its partial derivative with respect to its slope and its intercept, then subtracting this from the slope beta (denoted theta in the case of the equation below). The partial derivative is scaled by a desired learning rate (hyperparameter) and this process is repeated until a convergence at the minimum.</p>
<p><img src="vertopal_36b40601c4794c6b8b7ee372dc698101/10255763d97490ec18f218c5d815c13a9dc8d915.png" alt="xgbcostfunctionderivative" /></p>
<p>Source: <a href="https://medium.com/analytics-vidhya/what-makes-xgboost-so-extreme-e1544a4433bb" class="uri">https://medium.com/analytics-vidhya/what-makes-xgboost-so-extreme-e1544a4433bb</a></p>
</section>
<div class="cell code" data-execution_count="13" id="7zCnKQdHLCNc">
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extreme Gradient Regression</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>xgbr <span class="op">=</span> XGBRegressor(objective<span class="op">=</span><span class="st">&#39;reg:squarederror&#39;</span>, n_estimators<span class="op">=</span><span class="dv">100</span>, reg_lambda<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="dv">1</span>, gamma<span class="op">=</span><span class="dv">10</span>, max_depth<span class="op">=</span><span class="dv">3</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="22" id="k8pWPy0wEf_W">
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Model Set 1</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Linear (lsr), Decision Tree (dtr), Random Forest (rfr), Extreme Gradient (xgr), </span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> RunModel1(model, x , y, scaler, split):</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  mse_model <span class="op">=</span> []</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>  mae_model <span class="op">=</span> []</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>  r2_model <span class="op">=</span> []</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> idxtrain, idxtest <span class="kw">in</span> kf.split(x):</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    xtrain <span class="op">=</span> x[idxtrain]</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    ytrain <span class="op">=</span> y[idxtrain]</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    ytest <span class="op">=</span> y[idxtest]</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    xtest <span class="op">=</span> x[idxtest]</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    xtrain <span class="op">=</span> ss.fit_transform(xtrain)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    xtest <span class="op">=</span> ss.transform(xtest)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    model.fit(xtrain, ytrain)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> model.predict(xtest)</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    mse_model.append(mse(ytest, yhat))</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    mae_model.append(mae(ytest, yhat))</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    r2_model.append(r2(ytest, yhat))</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> np.mean(mse_model), np.mean(mae_model), np.mean(r2_model)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="23" id="wsXVETnDIylR">
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Model Set 2</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Loess, Boosted Loess</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> RunModel2(model, x , y, kern, tau, scaler, split, boost<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>  mse_model <span class="op">=</span> []</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>  mae_model <span class="op">=</span> []</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>  r2_model <span class="op">=</span> []</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> idxtrain, idxtest <span class="kw">in</span> kf.split(x):</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    xtrain <span class="op">=</span> x[idxtrain]</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    ytrain <span class="op">=</span> y[idxtrain]</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    ytest <span class="op">=</span> y[idxtest]</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    xtest <span class="op">=</span> x[idxtest]</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>    xtrain <span class="op">=</span> ss.fit_transform(xtrain)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>    xtest <span class="op">=</span> ss.transform(xtest)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> model(xtrain,ytrain, xtest, kern, tau<span class="op">=</span>tau, intercept<span class="op">=</span><span class="va">True</span>, boost<span class="op">=</span>boost)</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>    mse_model.append(mse(ytest, yhat))</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>    mae_model.append(mae(ytest, yhat))</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>    r2_model.append(r2(ytest, yhat))</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> np.mean(mse_model), np.mean(mae_model), np.mean(r2_model)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="24" id="09vAua6eIyoE">
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Model Set 3</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Neural Network</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> RunNN(model, x , y, scaler, split, val_split<span class="op">=</span><span class="fl">0.25</span>, epoch<span class="op">=</span><span class="dv">500</span>, batch<span class="op">=</span><span class="dv">20</span>):</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>  mse_model <span class="op">=</span> []</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>  mae_model <span class="op">=</span> []</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>  r2_model <span class="op">=</span> []</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> idxtrain, idxtest <span class="kw">in</span> kf.split(x):</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    xtrain <span class="op">=</span> x[idxtrain]</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    ytrain <span class="op">=</span> y[idxtrain]</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    ytest <span class="op">=</span> y[idxtest]</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    xtest <span class="op">=</span> x[idxtest]</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    xtrain <span class="op">=</span> ss.fit_transform(xtrain)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    xtest <span class="op">=</span> ss.transform(xtest)</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    model.fit(xtrain, ytrain, validation_split<span class="op">=</span>val_split, epochs<span class="op">=</span>epoch, batch_size<span class="op">=</span>batch, verbose<span class="op">=</span><span class="dv">0</span>, callbacks<span class="op">=</span>[es])</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> seq.predict(xtest)</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    mse_model.append(mse(ytest, yhat))</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    mae_model.append(mae(ytest, yhat))</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    r2_model.append(r2(ytest, yhat))</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> np.mean(mse_model), np.mean(mae_model), np.mean(r2_model)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="26" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="un1_Q_sGIyxu" data-outputId="60e454c1-1d2f-4e37-deb3-3655276a199a">
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>mse_lsr, mae_lsr, r2_lsr <span class="op">=</span> RunModel1(lsr, x, y, ss, kf)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Squared Error for Least-Squares Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mse_lsr))</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Absolute Error for Least-Squares Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mae_lsr))</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Coefficient of Determination for Least-Squares Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(r2_lsr))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The Cross-validated Mean Squared Error for Least-Squares Regression is : 37.23940104890824
The Cross-validated Mean Absolute Error for Least-Squares Regression is : 4.020970004960848
The Cross-validated Coefficient of Determination for Least-Squares Regression is : 0.5478240461818417
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="27" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="bNIxecxSPvis" data-outputId="a757e604-4228-48b4-9c56-4423cb297ae5">
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>mse_dtr, mae_dtr, r2_dtr <span class="op">=</span> RunModel1(dtr, x, y, ss, kf)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Squared Error for Decision Tree Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mse_dtr))</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Absolute Error for Decision Tree Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mae_dtr))</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Coefficient of Determination for Decision Tree Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(r2_dtr))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The Cross-validated Mean Squared Error for Decision Tree Regression is : 35.18217909437036
The Cross-validated Mean Absolute Error for Decision Tree Regression is : 4.063618925443233
The Cross-validated Coefficient of Determination for Decision Tree Regression is : 0.5680960234893112
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="28" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="9vbMtQ-gPvlO" data-outputId="2e21e9e9-b28e-46c9-8fd6-aa5abe51d941">
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>mse_rfr, mae_rfr, r2_rfr <span class="op">=</span> RunModel1(rfr, x, y, ss, kf)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Squared Error for Random Forest Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mse_rfr))</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Absolute Error for Random Forest Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mae_rfr))</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Coefficient of Determination for Random Forest Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(r2_rfr))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The Cross-validated Mean Squared Error for Random Forest Regression is : 31.9639600875443
The Cross-validated Mean Absolute Error for Random Forest Regression is : 3.8578840078128542
The Cross-validated Coefficient of Determination for Random Forest Regression is : 0.6121888076614384
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="34" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="Ey9U_yFtadp2" data-outputId="3bd8e492-0997-46db-e11a-9a2274a8c2ec">
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>mse_seq, mae_seq, r2_seq <span class="op">=</span> RunNN(seq, x, y, ss, kf)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Squared Error for Neural Network is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mse_seq))</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Absolute Error for Neural Network is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mae_seq))</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Coefficient of Determination for Neural Network is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(r2_seq))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The Cross-validated Mean Squared Error for Neural Network is : 85.57445466742146
The Cross-validated Mean Absolute Error for Neural Network is : 5.030748784209109
The Cross-validated Coefficient of Determination for Neural Network is : -0.1203951433644184
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="31" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="Bpwd9uFhPvqL" data-outputId="dc1a2bfc-6ca0-473f-8a65-a342bbea9659">
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>mse_lwr, mae_lwr, r2_lwr <span class="op">=</span> RunModel2(lwr, x, y, Tricubic, <span class="fl">0.9</span>, ss, kf)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Squared Error for Locally Weighted Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mse_lwr))</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Absolute Error for Locally Weighted Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mae_lwr))</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Coefficient of Determination for Locally Weighted Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(r2_lwr))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The Cross-validated Mean Squared Error for Locally Weighted Regression is : 26.597270697712815
The Cross-validated Mean Absolute Error for Locally Weighted Regression is : 3.3010239544041284
The Cross-validated Coefficient of Determination for Locally Weighted Regression is : 0.6845775749624277
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="32" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="yEPe6LkAZOu3" data-outputId="68f655f6-c0be-4c24-ce72-5cc592bb1a4d">
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>mse_blwr, mae_blwr, r2_blwr <span class="op">=</span> RunModel2(blwr, x, y, Quartic, <span class="fl">0.9</span>, ss, kf, dtr)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Squared Error for Locally Weighted Regression Boosted with Decision Trees is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mse_blwr))</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Absolute Error for Locally Weighted Regression Boosted with Decision Trees is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mae_blwr))</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Coefficient of Determination for Locally Weighted Regression Boosted with Decision Trees is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(r2_blwr))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The Cross-validated Mean Squared Error for Locally Weighted Regression Boosted with Decision Trees is : 26.943911216871744
The Cross-validated Mean Absolute Error for Locally Weighted Regression Boosted with Decision Trees is : 3.2946931437035536
The Cross-validated Coefficient of Determination for Locally Weighted Regression Boosted with Decision Trees is : 0.6813133952301352
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="33" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="YUuFpIi-Pvsk" data-outputId="b89387de-a721-4913-dab4-3fe89724c228">
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>mse_blwr, mae_blwr, r2_blwr <span class="op">=</span> RunModel2(blwr, x, y, Quartic, <span class="fl">0.9</span>, ss, kf, boost<span class="op">=</span>rfr)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Squared Error for Locally Weighted Regression Boosted with Random Forest is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mse_blwr))</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Absolute Error for Locally Weighted Regression Boosted with Random Forest is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mae_blwr))</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Coefficient of Determination for Locally Weighted Regression Boosted with Random Forest is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(r2_blwr))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The Cross-validated Mean Squared Error for Locally Weighted Regression Boosted with Random Forest is : 26.68176106594833
The Cross-validated Mean Absolute Error for Locally Weighted Regression Boosted with Random Forest is : 3.2491331849574685
The Cross-validated Coefficient of Determination for Locally Weighted Regression Boosted with Random Forest is : 0.6858306843421442
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="30" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="eK2wCvQhPvnl" data-outputId="317dfb2c-01e9-4a94-eb15-755bfeab0aab">
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>mse_xgbr, mae_xgbr, r2_xgbr <span class="op">=</span> RunModel1(xgbr, x, y, ss, kf)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Squared Error for Extreme Gradient Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mse_xgbr))</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Absolute Error for Extreme Gradient Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mae_xgbr))</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Coefficient of Determination for Extreme Gradient Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(r2_xgbr))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The Cross-validated Mean Squared Error for Extreme Gradient Regression is : 26.548227007953603
The Cross-validated Mean Absolute Error for Extreme Gradient Regression is : 3.217740893794725
The Cross-validated Coefficient of Determination for Extreme Gradient Regression is : 0.6886189666427519
</code></pre>
</div>
</div>
<div class="cell markdown" id="QsI5V3DfC0Ol">
<p>Overall, all of the models performed relatively poorly. Locally weighted regression performed the best out of the standard nonparametric models, performing marginally better than its primary competitor, random forest regression. On a side note, the ordinary linear regression did not fare so badly against the decision tree regression, which was a suprising result. The artificial neural network is a useless model and is unable to account for any of the explained variation in the data with a negative R^2 score. Strangely, the boosted versions of the locally weighted regression, both the decision tree and random forest, performed slightly poorer than the standard model, which is to say the current state that I constructed added no predicitve power. Unfortunately, the same can be said for the extreme gradient boosting, which performed the best out of all of the models. Overall, the boosted models did perform marginally better than the standard models; however, I suspect that they are ill-equipped to make solid predictions for this particular data.</p>
</div>
<section id="concrete-data" class="cell markdown" id="Kki_Q2pCC0UR">
<h3>Concrete Data</h3>
<p>The second dataset I will try to model will be the Boston Housing Prices dataset, which can be found here: <a href="https://www.kaggle.com/elikplim/concrete-compressive-strength-data-set" class="uri">https://www.kaggle.com/elikplim/concrete-compressive-strength-data-set</a></p>
</section>
<div class="cell code" data-execution_count="41" data-colab="{&quot;height&quot;:206,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="ghJGk4vW3qBn" data-outputId="dca4e9af-6276-4a57-a55b-6d356a760dbb">
<div class="sourceCode" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Data</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>concrete <span class="op">=</span> pd.read_csv(<span class="st">&#39;drive/MyDrive/Data/concrete.csv&#39;</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>concrete.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="41">

  <div id="df-d90a33d5-988f-42dd-b78e-53e078367cfb">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cement</th>
      <th>slag</th>
      <th>ash</th>
      <th>water</th>
      <th>superplastic</th>
      <th>coarseagg</th>
      <th>fineagg</th>
      <th>age</th>
      <th>strength</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>540.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>162.0</td>
      <td>2.5</td>
      <td>1040.0</td>
      <td>676.0</td>
      <td>28</td>
      <td>79.99</td>
    </tr>
    <tr>
      <th>1</th>
      <td>540.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>162.0</td>
      <td>2.5</td>
      <td>1055.0</td>
      <td>676.0</td>
      <td>28</td>
      <td>61.89</td>
    </tr>
    <tr>
      <th>2</th>
      <td>332.5</td>
      <td>142.5</td>
      <td>0.0</td>
      <td>228.0</td>
      <td>0.0</td>
      <td>932.0</td>
      <td>594.0</td>
      <td>270</td>
      <td>40.27</td>
    </tr>
    <tr>
      <th>3</th>
      <td>332.5</td>
      <td>142.5</td>
      <td>0.0</td>
      <td>228.0</td>
      <td>0.0</td>
      <td>932.0</td>
      <td>594.0</td>
      <td>365</td>
      <td>41.05</td>
    </tr>
    <tr>
      <th>4</th>
      <td>198.6</td>
      <td>132.4</td>
      <td>0.0</td>
      <td>192.0</td>
      <td>0.0</td>
      <td>978.4</td>
      <td>825.5</td>
      <td>360</td>
      <td>44.30</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-d90a33d5-988f-42dd-b78e-53e078367cfb')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-d90a33d5-988f-42dd-b78e-53e078367cfb button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-d90a33d5-988f-42dd-b78e-53e078367cfb');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell markdown" id="XkpeOfyLR5YI">
<p>Like before, I will choose 3 feature variables to predict the compressive strength of the concrete: the amount of the cement component, the amount of the slag component, and the amount of the water component. To get an idea of the immediate linear correlation coefficients and distributions of the feature and response variables, I will again create a heatmap and a pairplot.</p>
</div>
<div class="cell code" data-execution_count="56" data-colab="{&quot;height&quot;:852,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="RDvh62G9IWX8" data-outputId="500c81a5-1742-4380-a955-8e35c104b4cc">
<div class="sourceCode" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Select variables and plot data</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> concrete[[<span class="st">&#39;cement&#39;</span>,<span class="st">&#39;slag&#39;</span>,<span class="st">&#39;water&#39;</span>]].values</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> concrete[<span class="st">&#39;strength&#39;</span>].values</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlation Heatmap</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>irrel_col <span class="op">=</span> [<span class="st">&#39;ash&#39;</span>,<span class="st">&#39;superplastic&#39;</span>,<span class="st">&#39;coarseagg&#39;</span>,<span class="st">&#39;fineagg&#39;</span>,<span class="st">&#39;age&#39;</span>]</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>concrete_select <span class="op">=</span> concrete.drop(columns<span class="op">=</span>irrel_col)</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> concrete_select.corr()</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> np.triu(c)</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">8</span>))</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>sns.heatmap(c, mask<span class="op">=</span>mask, annot<span class="op">=</span><span class="va">True</span>, annot_kws<span class="op">=</span>{<span class="st">&#39;fontsize&#39;</span>:<span class="dv">8</span>,<span class="st">&#39;weight&#39;</span>:<span class="st">&#39;bold&#39;</span>}, cmap<span class="op">=</span><span class="st">&#39;PuBu&#39;</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>            yticklabels<span class="op">=</span>[<span class="st">&#39; &#39;</span>] <span class="op">+</span> <span class="bu">list</span>(concrete_select.columns[<span class="dv">1</span>:]), xticklabels<span class="op">=</span>concrete_select.columns[:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>plt.tick_params(size<span class="op">=</span><span class="dv">0</span>, labelsize<span class="op">=</span><span class="dv">14</span>, pad<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Pairwise Linear Correlations&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;concrete_heat.png&#39;</span>)</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_36b40601c4794c6b8b7ee372dc698101/bf69307732d65a8a18d3aa7c936045d2d0a6becd.png" width="786" height="835" /></p>
</div>
</div>
<div class="cell code" data-execution_count="47" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="1Uoxiv0E-6TU" data-outputId="c56ea2d0-e91f-4d98-c878-598af5a105b0">
<div class="sourceCode" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">8</span>))</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>sns.pairplot(concrete_select)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;concrete_pair.png&#39;</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<pre><code>&lt;Figure size 960x960 with 0 Axes&gt;</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_36b40601c4794c6b8b7ee372dc698101/a75ef388cf021512a6a8a68f9fbd2976abc0a765.png" width="1182" height="1180" /></p>
</div>
</div>
<div class="cell code" data-execution_count="48" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="G0jbXPPlPU3E" data-outputId="8949a66d-1508-4567-9280-df6c62b17b05">
<div class="sourceCode" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>mse_lsr, mae_lsr, r2_lsr <span class="op">=</span> RunModel1(lsr, x, y, ss, kf)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Squared Error for Least-Squares Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mse_lsr))</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Absolute Error for Least-Squares Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mae_lsr))</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Coefficient of Determination for Least-Squares Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(r2_lsr))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The Cross-validated Mean Squared Error for Least-Squares Regression is : 167.78526376603222
The Cross-validated Mean Absolute Error for Least-Squares Regression is : 10.429406509600094
The Cross-validated Coefficient of Determination for Least-Squares Regression is : 0.38806908236831456
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="49" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="hxSbTvXeAMQx" data-outputId="080e0791-4712-4559-a107-f2f1ef80989b">
<div class="sourceCode" id="cb47"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>mse_dtr, mae_dtr, r2_dtr <span class="op">=</span> RunModel1(dtr, x, y, ss, kf)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Squared Error for Decision Tree Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mse_dtr))</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Absolute Error for Decision Tree Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mae_dtr))</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Coefficient of Determination for Decision Tree Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(r2_dtr))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The Cross-validated Mean Squared Error for Decision Tree Regression is : 196.55510778069464
The Cross-validated Mean Absolute Error for Decision Tree Regression is : 11.42242710516928
The Cross-validated Coefficient of Determination for Decision Tree Regression is : 0.283131231488064
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="50" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="juXMgjHMAQ4B" data-outputId="c2b29868-6a22-4fcf-8f23-9ce112d4ea6f">
<div class="sourceCode" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>mse_rfr, mae_rfr, r2_rfr <span class="op">=</span> RunModel1(rfr, x, y, ss, kf)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Squared Error for Random Forest Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mse_rfr))</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Absolute Error for Random Forest Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mae_rfr))</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Coefficient of Determination for Random Forest Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(r2_rfr))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The Cross-validated Mean Squared Error for Random Forest Regression is : 185.20401382173023
The Cross-validated Mean Absolute Error for Random Forest Regression is : 11.121562873963494
The Cross-validated Coefficient of Determination for Random Forest Regression is : 0.3260469998620026
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="55" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="iz1VrCrZCWEY" data-outputId="968d205c-ab7e-42c3-961a-d710db50f77e">
<div class="sourceCode" id="cb51"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>mse_seq, mae_seq, r2_seq <span class="op">=</span> RunNN(seq, x, y, ss, kf)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Squared Error for Neural Network is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mse_seq))</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Absolute Error for Neural Network is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mae_seq))</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Coefficient of Determination for Neural Network is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(r2_seq))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The Cross-validated Mean Squared Error for Neural Network is : 185.4012886376533
The Cross-validated Mean Absolute Error for Neural Network is : 11.223063258865505
The Cross-validated Coefficient of Determination for Neural Network is : 0.32458313308094616
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="52" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="ELKlnX2wBRtM" data-outputId="e8923e21-6f0a-4730-ce26-e11831cc2c52">
<div class="sourceCode" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>mse_lwr, mae_lwr, r2_lwr <span class="op">=</span> RunModel2(lwr, x, y, Tricubic, <span class="fl">0.9</span>, ss, kf)</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Squared Error for Locally Weighted Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mse_lwr))</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Absolute Error for Locally Weighted Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mae_lwr))</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Coefficient of Determination for Locally Weighted Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(r2_lwr))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The Cross-validated Mean Squared Error for Locally Weighted Regression is : 146.4227649591804
The Cross-validated Mean Absolute Error for Locally Weighted Regression is : 9.768092527277217
The Cross-validated Coefficient of Determination for Locally Weighted Regression is : 0.4654909181670496
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="53" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="PJ0ObzztCEqZ" data-outputId="0f450be6-18b8-439b-f2d2-f564ddc9bb7b">
<div class="sourceCode" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>mse_blwr, mae_blwr, r2_blwr <span class="op">=</span> RunModel2(blwr, x, y, Quartic, <span class="fl">0.9</span>, ss, kf, dtr)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Squared Error for Locally Weighted Regression Boosted with Decision Trees is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mse_blwr))</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Absolute Error for Locally Weighted Regression Boosted with Decision Trees is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mae_blwr))</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Coefficient of Determination for Locally Weighted Regression Boosted with Decision Trees is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(r2_blwr))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The Cross-validated Mean Squared Error for Locally Weighted Regression Boosted with Decision Trees is : 141.5780947490901
The Cross-validated Mean Absolute Error for Locally Weighted Regression Boosted with Decision Trees is : 9.551662686619025
The Cross-validated Coefficient of Determination for Locally Weighted Regression Boosted with Decision Trees is : 0.4829019098259071
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="54" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="B3tzVepMBqhN" data-outputId="8d994d76-8c69-4b27-a257-6d505d43feab">
<div class="sourceCode" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>mse_blwr, mae_blwr, r2_blwr <span class="op">=</span> RunModel2(blwr, x, y, Quartic, <span class="fl">0.9</span>, ss, kf, boost<span class="op">=</span>rfr)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Squared Error for Locally Weighted Regression Boosted with Random Forest is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mse_blwr))</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Absolute Error for Locally Weighted Regression Boosted with Random Forest is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mae_blwr))</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Coefficient of Determination for Locally Weighted Regression Boosted with Random Forest is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(r2_blwr))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The Cross-validated Mean Squared Error for Locally Weighted Regression Boosted with Random Forest is : 142.51517506407464
The Cross-validated Mean Absolute Error for Locally Weighted Regression Boosted with Random Forest is : 9.620449887420262
The Cross-validated Coefficient of Determination for Locally Weighted Regression Boosted with Random Forest is : 0.47975481741057535
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="51" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="GZaziG1-AY31" data-outputId="15555f66-6dea-4313-c826-35f4b378ba12">
<div class="sourceCode" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>mse_xgbr, mae_xgbr, r2_xgbr <span class="op">=</span> RunModel1(xgbr, x, y, ss, kf)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Squared Error for Extreme Gradient Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mse_xgbr))</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Mean Absolute Error for Extreme Gradient Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(mae_xgbr))</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The Cross-validated Coefficient of Determination for Extreme Gradient Regression is : &#39;</span> <span class="op">+</span> <span class="bu">str</span>(r2_xgbr))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The Cross-validated Mean Squared Error for Extreme Gradient Regression is : 142.3439960678086
The Cross-validated Mean Absolute Error for Extreme Gradient Regression is : 9.609343509785178
The Cross-validated Coefficient of Determination for Extreme Gradient Regression is : 0.4814444923220341
</code></pre>
</div>
</div>
<div class="cell markdown" id="LDQErmtaPKkP">
<p>Like before, all of the models performed relatively poorly, though much more poorly than with the first data. Again, locally weighted regression performed the best out of the standard nonparametric models. However, even more strangely than with the last data, ordinary linear regression performed marginally better than both the decision tree and random forest regressions, though I suspect with a little optimization, these two could surpass it. The artificial neural network handled this data much better than the last, and achieved a result that competes with the nonparametric models. In this case, both of the boosted versions of the locally weighted regression did perform slightly better than the standard model. The extreme gradient regression again performed the best out of all of the models. Overall, the boosted models perform marginally better than the standard models again. I suspect most of the differences in the results between the two data are result of my variable selection.</p>
</div>
<section id="limitations" class="cell markdown" id="ckJG63f7cn5E">
<h2>Limitations</h2>
<p>As previously mentioned, all of the tested models were ill-suited to both data, and the next priority task is to perform adequate variable selection. Furthermore, it would be beneficial to perform optimization through hyperparameter selection loops, to determine the best construction of each model for each dataset. Overall, I can conclude that boosting is effective, and for this to become more obvious, I suspect that I need to improve it with repeated boostings.</p>
</section>
<div class="cell code" id="x9uvK0jSdMOw">
<div class="sourceCode" id="cb61"><pre class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
</body>
</html>
